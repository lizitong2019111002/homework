{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7ef3e3e",
   "metadata": {},
   "source": [
    "## 李子桐 2019111002"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa10ef93",
   "metadata": {},
   "source": [
    "a. Because sometimes it cannot be said that A and B are related, and it cannot be said that the occurrence of A has an impact on B. For example, when PB is originally high, the probability of B occurrence when A occurs is inherently high, and it cannot be explained that they are related. . LIFT and CONVICTION can explain the relevance of A and B. If lift=1, A and B are independent, lift<1, then the probability of A occurring when B occurs, and lift>1, then the probability of A occurring when B occurs Will improve. Conv=1, when A and B are independent, when conv>1, when B occurs, the probability of A will decrease; when conv<1, when B occurs, the probability of A will increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929400ee",
   "metadata": {},
   "source": [
    "b.Confidence is asymmetric\n",
    "Con(A-B)=support(AB)/support(A)\n",
    "Con(B-A)=support(AB)/support(B)\n",
    "If P(A)=/P(B) then asymmetric\n",
    "\n",
    "Lift is symmetric\n",
    "Lift(A-B)=support(AB)/support(A)*support(B)\n",
    "Lift(B-A)=support(AB), support(B)*support(A)\n",
    "Commutative law of multiplication\n",
    "\n",
    "Conviction is asymmetric\n",
    "Conv(A-B)=Nsupport(A)-support(A)*support(B)/support(A)-support(AB)\n",
    "Conv(B-A)=Nsupport(B)-support(B)*support(A)/support(B)-support(BA)\n",
    "Support(AB)!=support(A)*support(B)\n",
    "So asymmetric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5ac916",
   "metadata": {},
   "source": [
    "c.Conviction has this property\n",
    "When conf=1, A must happen when B occurs, at this time lift=1/support(B),conviction=1-support(B)/0. When support tends to 0, the denominator of lift gradually tends to 0, and the denominator of conviction is 0, so conviction is larger at this time. When support tends to 1, lift gradually tends to 1, and in this process conviction always tends to positive infinity. In summary, conviction is the largest, so conviction has this property."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e2993e",
   "metadata": {},
   "source": [
    "The codes for d and e are below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df6d94be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  :  579\n",
      "2  :  1104\n",
      "3  :  216\n",
      "[(\"{'DAI93865'}->{'FRO40251'}\", 1.0), (\"{'GRO85051'}->{'FRO40251'}\", 0.9991554054054054), (\"{'ELE12951'}->{'FRO40251'}\", 0.9901960784313726), (\"{'FRO92469'}->{'FRO40251'}\", 0.9886075949367089), (\"{'DAI88079'}->{'FRO40251'}\", 0.9875930521091811)]\n",
      "[(\"{'SNA80324', 'GRO85051'}->{'FRO40251'}\", 1.0), (\"{'SNA45677', 'GRO85051'}->{'FRO40251'}\", 1.0), (\"{'GRO73461', 'GRO85051'}->{'FRO40251'}\", 1.0), (\"{'GRO38814', 'GRO85051'}->{'FRO40251'}\", 1.0), (\"{'GRO21487', 'GRO85051'}->{'FRO40251'}\", 1.0)]\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "DEBUG = 1\n",
    "\n",
    "\n",
    "def Dprint(info):\n",
    "    if DEBUG:\n",
    "        print(info)\n",
    "\n",
    "\n",
    "def generate_next_c(f_k, k):\n",
    "    next_c = [var1 | var2 for index, var1 in enumerate(f_k) for var2 in f_k[index + 1:] if\n",
    "              list(var1)[:k - 2] == list(var2)[:k - 2]]\n",
    "    return next_c\n",
    "\n",
    "\n",
    "def generate_f_k(sc, c_k, shared_itemset, sup):\n",
    "    def get_sup(x):\n",
    "        x_sup = len([1 for t in shared_itemset.value if x.issubset(t)])\n",
    "        if x_sup >= sup:\n",
    "            return x, x_sup\n",
    "        else:\n",
    "            return ()\n",
    "\n",
    "    f_k = sc.parallelize(c_k).map(get_sup).filter(lambda x: x).collect()\n",
    "    return f_k\n",
    "\n",
    "\n",
    "def apriori(sc, f_input, min_sup, max_k):\n",
    "    # read the raw data\n",
    "    data = sc.textFile(f_input)\n",
    "    # count the total number of samples\n",
    "    n_samples = data.count()\n",
    "    # min_sup to frequency\n",
    "    sup = min_sup\n",
    "    # split sort\n",
    "    itemset = data.map(lambda line: sorted(list(set([item for item in line.strip(\"\\n\").strip().split(' ')]))))\n",
    "    # share the whole itemset with all workers\n",
    "    shared_itemset = sc.broadcast(itemset.collect())\n",
    "    # store for all freq_k\n",
    "    frequent_itemset = []\n",
    "    # prepare candidate_1\n",
    "    k = 1\n",
    "    c_k = itemset.flatMap(lambda x: x).distinct().collect()\n",
    "    c_k = [{x} for x in c_k]\n",
    "\n",
    "    # when candidate_k is not empty\n",
    "    while len(c_k) > 0 and k <= max_k:\n",
    "        # generate freq_k\n",
    "        # Dprint(\"C{}: {}\".format(k, c_k))\n",
    "        f_k = generate_f_k(sc, c_k, shared_itemset, sup)\n",
    "        # Dprint(\"F{}: {}\".format(k, f_k))\n",
    "        print(k, \" : \", len(f_k))\n",
    "        frequent_itemset.append(f_k)\n",
    "        # generate candidate_k+1\n",
    "        k += 1\n",
    "        c_k = generate_next_c([set(item) for item in map(lambda x: x[0], f_k)], k)\n",
    "    sc.stop()\n",
    "    return frequent_itemset\n",
    "\n",
    "\n",
    "def get_three_item_conf(frequent_itemset):\n",
    "\n",
    "    dic_lst = []\n",
    "\n",
    "    for item_lst in frequent_itemset:\n",
    "        dic = {}\n",
    "        for item, val in item_lst:\n",
    "            dic[\",\".join(sorted(list(item)))] = val\n",
    "        dic_lst.append(dic)\n",
    "\n",
    "    frequent2 = dic_lst[1]\n",
    "    three_item_conf_dic = {}\n",
    "    for item, cnt in frequent_itemset[2]:\n",
    "        first_item, second_item, third_item = item\n",
    "        first_second_cnt = frequent2[\",\".join(sorted([first_item, second_item]))]\n",
    "        first_third_cnt = frequent2[\",\".join(sorted([first_item, third_item]))]\n",
    "        second_third_cnt = frequent2[\",\".join(sorted([second_item, third_item]))]\n",
    "\n",
    "        three_item_conf_dic[\"%s->%s\"%(str({first_item, second_item}), str({third_item}))] = cnt/first_second_cnt\n",
    "        three_item_conf_dic[\"%s->%s\"%(str({first_item, third_item}), str({second_item}))] = cnt/first_third_cnt\n",
    "        three_item_conf_dic[\"%s->%s\"%(str({second_item, third_item}), str({first_item}))] = cnt/second_third_cnt\n",
    "    return three_item_conf_dic\n",
    "\n",
    "\n",
    "def get_two_item_conf(frequent_itemset):\n",
    "\n",
    "    dic_lst = []\n",
    "\n",
    "    for item_lst in frequent_itemset:\n",
    "        dic = {}\n",
    "        for item,val in item_lst:\n",
    "            dic[str(item)] = val\n",
    "        dic_lst.append(dic)\n",
    "\n",
    "    frequent1 = dic_lst[0]\n",
    "    two_item_conf_dic = {}\n",
    "    for item, cnt in frequent_itemset[1]:\n",
    "        first_item, second_item = item\n",
    "        first_cnt = frequent1[str({first_item})]\n",
    "        second_cnt = frequent1[str({second_item})]\n",
    "        two_item_conf_dic[\"%s->%s\"%({first_item}, {second_item})] = cnt/first_cnt\n",
    "        two_item_conf_dic[\"%s->%s\"%({second_item}, {first_item})] = cnt/second_cnt\n",
    "    return two_item_conf_dic\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input = \"C:/Users/Administrator/Desktop/DS2/browsing_new.txt\"\n",
    "    frequent_itemset = apriori(SparkContext(appName=\"Spark Apriori\"), input, 100, 3)\n",
    "    two_item_conf_dic = get_two_item_conf(frequent_itemset)\n",
    "    three_item_conf_dic =get_three_item_conf(frequent_itemset)\n",
    "    two_item_conf_lst = sorted(two_item_conf_dic.items(), key=lambda kv:(kv[1], kv[0]), reverse=True)\n",
    "    three_item_conf_lst = sorted(three_item_conf_dic.items(), key=lambda kv:(kv[1], kv[0]), reverse=True)\n",
    "    print(two_item_conf_lst[0:5])\n",
    "    print(three_item_conf_lst[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed382f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
